{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Selecting random state for CSC\n\nThe CSC problem is non-convex. Therefore, the solution depends\non the initialization. Here, we show how to select the\nbest atoms amongst different initializations.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Authors: Mainak Jas <mainak.jas@telecom-paristech.fr>\n#          Tom Dupre La Tour <tom.duprelatour@telecom-paristech.fr>\n#          Umut Simsekli <umut.simsekli@telecom-paristech.fr>\n#          Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n#\n# License: BSD (3-clause)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "As before, let us first define the parameters of our model.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "n_times_atom = 64  # L\nn_times = 512  # T\nn_atoms = 2  # K\nn_trials = 100  # N\nn_iter = 50\n\nreg = 0.1"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Here, we simulate the data\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from alphacsc.simulate import simulate_data # noqa\nfrom scipy.stats import levy_stable # noqa\nfrom alphacsc import check_random_state # noqa\n\nrandom_state_simulate = 1\nX, ds_true, Z_true = simulate_data(n_trials, n_times, n_times_atom,\n                                   n_atoms, random_state_simulate)\n\n# Add stationary noise:\nfraction_corrupted = 0.02\nn_corrupted_trials = int(fraction_corrupted * n_trials)\n\nrng = check_random_state(random_state_simulate)\nX += 0.01 * rng.randn(*X.shape)\n\nidx_corrupted = rng.randint(0, n_trials,\n                            size=n_corrupted_trials)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Now, we run vanilla CSC on the data but with different initializations.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from alphacsc import learn_d_z # noqa\n\npobjs, d_hats = list(), list()\nfor random_state in range(5):\n    print('\\nRandom state: %d' % random_state)\n    pobj, times, d_hat, Z_hat = learn_d_z(\n        X, n_atoms, n_times_atom, reg=reg, n_iter=n_iter,\n        solver_d_kwargs=dict(factr=100), random_state=random_state,\n        n_jobs=1, verbose=1)\n    pobjs.append(pobj[-1])\n    d_hats.append(d_hat)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "As we loop through the random states, we save the objective value `pobj`\nat the last iteration of the algorithm.\n\nNow, let us look at the atoms for different initializations.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import matplotlib.pyplot as plt # noqa\nfig, axes = plt.subplots(1, 5, figsize=(17, 3), sharex=True, sharey=True)\nfor ax, this_pobjs, d_hat in zip(axes, pobjs, d_hats):\n    ax.plot(d_hat.T)\n    ax.plot(ds_true.T, 'k--')\n    ax.set_title('pobj: %0.2f' % this_pobjs)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Note that lower the objective value, the better is the recovered atom.\nThis is one reason why using a concrete mathematical objective function as in\nconvolutional sparse coding is superior to heuristic methods.\nNow, we select the best atom amongst them.\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import numpy as np # noqa\n\nplt.figure()\nplt.plot(d_hats[np.argmin(pobjs)].T)\nplt.plot(ds_true.T, 'k--')\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.13", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}