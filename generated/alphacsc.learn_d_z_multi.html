<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>alphacsc.learn_d_z_multi &#8212; alphacsc 0.2dev documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="alphacsc.learn_d_z_weighted" href="alphacsc.learn_d_z_weighted.html" />
    <link rel="prev" title="alphacsc.learn_d_z" href="alphacsc.learn_d_z.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          alphacsc</a>
        <span class="navbar-text navbar-version pull-left"><b>0.2dev</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../models.html">Models</a></li>
                <li><a href="../auto_examples/index.html">Examples</a></li>
                <li><a href="../api.html">API</a></li>
                <li><a href="https://github.com/alphacsc/alphacsc">GitHub</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">alphaCSC: Convolution sparse coding for time-series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">Model descriptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/alphacsc/alphacsc">Fork alphacsc on Github</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="alphacsc-learn-d-z-multi">
<h1>alphacsc.learn_d_z_multi<a class="headerlink" href="#alphacsc-learn-d-z-multi" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="alphacsc.learn_d_z_multi">
<code class="descclassname">alphacsc.</code><code class="descname">learn_d_z_multi</code><span class="sig-paren">(</span><em>X</em>, <em>n_atoms</em>, <em>n_times_atom</em>, <em>n_iter=60</em>, <em>n_jobs=1</em>, <em>lmbd_max='fixed'</em>, <em>reg=0.1</em>, <em>loss='l2'</em>, <em>loss_params={'gamma': 0.1</em>, <em>'ordar': 10</em>, <em>'sakoe_chiba_band': 10}</em>, <em>rank1=True</em>, <em>uv_constraint='separate'</em>, <em>eps=1e-10</em>, <em>algorithm='batch'</em>, <em>algorithm_params={}</em>, <em>detrending=None</em>, <em>detrending_params={}</em>, <em>solver_z='l-bfgs'</em>, <em>solver_z_kwargs={}</em>, <em>solver_d='alternate_adaptive'</em>, <em>solver_d_kwargs={}</em>, <em>D_init=None</em>, <em>D_init_params={}</em>, <em>unbiased_z_hat=False</em>, <em>use_sparse_z=False</em>, <em>stopping_pobj=None</em>, <em>raise_on_increase=True</em>, <em>verbose=10</em>, <em>callback=None</em>, <em>random_state=None</em>, <em>name='DL'</em>, <em>window=False</em><span class="sig-paren">)</span><a class="headerlink" href="#alphacsc.learn_d_z_multi" title="Permalink to this definition">¶</a></dt>
<dd><p>Multivariate Convolutional Sparse Coding with optional rank-1 constraint</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array, shape (n_trials, n_channels, n_times)</p>
<blockquote>
<div><p>The data on which to perform CSC.</p>
</div></blockquote>
<p><strong>n_atoms</strong> : int</p>
<blockquote>
<div><p>The number of atoms to learn.</p>
</div></blockquote>
<p><strong>n_times_atom</strong> : int</p>
<blockquote>
<div><p>The support of the atom.</p>
</div></blockquote>
<p><strong>reg</strong> : float</p>
<blockquote>
<div><p>The regularization parameter</p>
</div></blockquote>
<p><strong>lmbd_max</strong> : ‘fixed’ | ‘scaled’ | ‘per_atom’ | ‘shared’</p>
<blockquote>
<div><dl class="docutils">
<dt>If not fixed, adapt the regularization rate as a ratio of lambda_max:</dt>
<dd><ul class="first last">
<li><p class="first">‘scaled’: the regularization parameter is fixed as a ratio of its
maximal value at init __ie__</p>
<blockquote>
<div><p><a href="#id1"><span class="problematic" id="id2">reg_</span></a> = reg * <a href="#id3"><span class="problematic" id="id4">lmbd_</span></a>max(uv_init)</p>
</div></blockquote>
</li>
<li><p class="first">‘shared’: the regularization parameter is set at each iteration as
a ratio of its maximal value for the current dictionary estimate
__ie__ <a href="#id5"><span class="problematic" id="id6">reg_</span></a> = reg * <a href="#id7"><span class="problematic" id="id8">lmbd_</span></a>max(uv_hat)</p>
</li>
<li><p class="first">‘per_atom’: the regularization parameter is set per atom and at
each iteration as a ratio of its maximal value for this atom __ie__</p>
<blockquote>
<div><p>reg_[k] = reg * <a href="#id9"><span class="problematic" id="id10">lmbd_</span></a>max(uv_hat[k])</p>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
</div></blockquote>
<p><strong>n_iter</strong> : int</p>
<blockquote>
<div><p>The number of coordinate-descent iterations.</p>
</div></blockquote>
<p><strong>n_jobs</strong> : int</p>
<blockquote>
<div><p>The number of parallel jobs.</p>
</div></blockquote>
<p><strong>loss</strong> : ‘l2’ | ‘dtw’</p>
<blockquote>
<div><p>Loss for the data-fit term. Either the norm l2 or the soft-DTW.</p>
</div></blockquote>
<p><strong>loss_params</strong> : dict</p>
<blockquote>
<div><p>Parameters of the loss</p>
</div></blockquote>
<p><strong>rank1</strong> : boolean</p>
<blockquote>
<div><p>If set to True, learn rank 1 dictionary atoms.</p>
</div></blockquote>
<p><strong>uv_constraint</strong> : str in {‘joint’ | ‘separate’}</p>
<blockquote>
<div><p>The kind of norm constraint on the atoms:
If ‘joint’, the constraint is norm_2([u, v]) &lt;= 1
If ‘separate’, the constraint is norm_2(u) &lt;= 1 and norm_2(v) &lt;= 1</p>
</div></blockquote>
<p><strong>eps</strong> : float</p>
<blockquote>
<div><p>Stopping criterion. If the cost descent after a uv and a z update is
smaller than eps, return.</p>
</div></blockquote>
<p><strong>algorithm</strong> : ‘batch’ | ‘greedy’ | ‘online’</p>
<blockquote>
<div><p>Dictionary learning algorithm.</p>
</div></blockquote>
<p><strong>algorithm_params</strong> : dict</p>
<blockquote>
<div><dl class="docutils">
<dt>Parameters for the global algorithm used to learn the dictionary:</dt>
<dd><dl class="first last docutils">
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Forgetting factor for online learning. If set to 0, the learning is
stochastic and each D-step is independent from the previous steps.
When set to 1, each the previous values z_hat - computed with
different dictionary - have the same weight as the current one.
This factor should be large enough to ensure convergence but to
large factor can lead to sub-optimal minima.</p>
</dd>
<dt>batch_selection <span class="classifier-delimiter">:</span> <span class="classifier">‘random’ | ‘cyclic’</span></dt>
<dd><p class="first last">The batch selection strategy for online learning. The batch are
either selected randomly among all samples (without replacement) or
in a cyclic way.</p>
</dd>
<dt>batch_size <span class="classifier-delimiter">:</span> <span class="classifier">int in [1, n_trials]</span></dt>
<dd><p class="first last">Size of the batch used in online learning. Increasing it
regularizes the dictionary learning as there is less variance for
the successive estimates. But it also increases the computational
cost as more coding signals z_hat must be estimate at each
iteration.</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<p><strong>solver_z</strong> : str</p>
<blockquote>
<div><p>The solver to use for the z update. Options are
‘l-bfgs’ (default) | “lgcd”</p>
</div></blockquote>
<p><strong>solver_z_kwargs</strong> : dict</p>
<blockquote>
<div><p>Additional keyword arguments to pass to update_z_multi</p>
</div></blockquote>
<p><strong>solver_d</strong> : str</p>
<blockquote>
<div><p>The solver to use for the d update. Options are
‘alternate’ | ‘alternate_adaptive’ (default) | ‘joint’</p>
</div></blockquote>
<p><strong>solver_d_kwargs</strong> : dict</p>
<blockquote>
<div><p>Additional keyword arguments to provide to update_d</p>
</div></blockquote>
<p><strong>D_init</strong> : str or array, shape (n_atoms, n_channels + n_times_atoms) or                            shape (n_atoms, n_channels, n_times_atom)</p>
<blockquote>
<div><p>The initial atoms or an initialization scheme in {‘kmeans’ | ‘ssa’ |
‘chunks’ | ‘random’}.</p>
</div></blockquote>
<p><strong>D_init_params</strong> : dict</p>
<blockquote>
<div><p>Dictionnary of parameters for the kmeans init method.</p>
</div></blockquote>
<p><strong>unbiased_z_hat</strong> : boolean</p>
<blockquote>
<div><p>If set to True, the value of the non-zero coefficients in the returned
z_hat are recomputed with reg=0 on the frozen support.</p>
</div></blockquote>
<p><strong>use_sparse_z</strong> : boolean</p>
<blockquote>
<div><p>Use sparse lil_matrices to store the activations.</p>
</div></blockquote>
<p><strong>verbose</strong> : int</p>
<blockquote>
<div><p>The verbosity level.</p>
</div></blockquote>
<p><strong>callback</strong> : func</p>
<blockquote>
<div><p>A callback function called at the end of each loop of the
coordinate descent.</p>
</div></blockquote>
<p><strong>random_state</strong> : int | None</p>
<blockquote>
<div><p>The random state.</p>
</div></blockquote>
<p><strong>raise_on_increase</strong> : boolean</p>
<blockquote>
<div><p>Raise an error if the objective function increase</p>
</div></blockquote>
<p><strong>window</strong> : boolean</p>
<blockquote>
<div><p>If True, re-parametrizes the atoms with a temporal Tukey window.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>pobj</strong> : list</p>
<blockquote>
<div><p>The objective function value at each step of the coordinate descent.</p>
</div></blockquote>
<p><strong>times</strong> : list</p>
<blockquote>
<div><p>The cumulative time for each iteration of the coordinate descent.</p>
</div></blockquote>
<p><strong>uv_hat</strong> : array, shape (n_atoms, n_channels + n_times_atom)</p>
<blockquote>
<div><p>The atoms to learn from the data.</p>
</div></blockquote>
<p><strong>z_hat</strong> : array, shape (n_trials, n_atoms, n_times_valid)</p>
<blockquote class="last">
<div><p>The sparse activation matrix.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2017-2018, Mainak Jas.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>