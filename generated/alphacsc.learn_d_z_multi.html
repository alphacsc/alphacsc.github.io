<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>alphacsc.learn_d_z_multi &#8212; alphacsc 0.3.dev documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="alphacsc.learn_d_z_weighted" href="alphacsc.learn_d_z_weighted.html" />
    <link rel="prev" title="alphacsc.learn_d_z" href="alphacsc.learn_d_z.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          alphacsc</a>
        <span class="navbar-text navbar-version pull-left"><b>0.3.dev</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../models.html">Models</a></li>
                <li><a href="../auto_examples/index.html">Examples</a></li>
                <li><a href="../api.html">API</a></li>
                <li><a href="https://github.com/alphacsc/alphacsc">GitHub</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">alphaCSC: Convolution sparse coding for time-series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">Model descriptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/alphacsc/alphacsc">Fork alphacsc on Github</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="alphacsc-learn-d-z-multi">
<h1>alphacsc.learn_d_z_multi<a class="headerlink" href="#alphacsc-learn-d-z-multi" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="alphacsc.learn_d_z_multi">
<code class="descclassname">alphacsc.</code><code class="descname">learn_d_z_multi</code><span class="sig-paren">(</span><em>X</em>, <em>n_atoms</em>, <em>n_times_atom</em>, <em>n_iter=60</em>, <em>n_jobs=1</em>, <em>lmbd_max='fixed'</em>, <em>reg=0.1</em>, <em>loss='l2'</em>, <em>loss_params={'gamma': 0.1</em>, <em>'ordar': 10</em>, <em>'sakoe_chiba_band': 10}</em>, <em>rank1=True</em>, <em>uv_constraint='separate'</em>, <em>eps=1e-10</em>, <em>algorithm='batch'</em>, <em>algorithm_params={}</em>, <em>detrending=None</em>, <em>detrending_params={}</em>, <em>solver_z='l-bfgs'</em>, <em>solver_z_kwargs={}</em>, <em>solver_d='alternate_adaptive'</em>, <em>solver_d_kwargs={}</em>, <em>D_init=None</em>, <em>D_init_params={}</em>, <em>unbiased_z_hat=False</em>, <em>use_sparse_z=False</em>, <em>stopping_pobj=None</em>, <em>raise_on_increase=True</em>, <em>verbose=10</em>, <em>callback=None</em>, <em>random_state=None</em>, <em>name='DL'</em>, <em>window=False</em>, <em>sort_atoms=False</em><span class="sig-paren">)</span><a class="headerlink" href="#alphacsc.learn_d_z_multi" title="Permalink to this definition">¶</a></dt>
<dd><p>Multivariate Convolutional Sparse Coding with optional rank-1 constraint</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_trials, n_channels, n_times)</span></dt>
<dd><p class="first last">The data on which to perform CSC.</p>
</dd>
<dt><strong>n_atoms</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The number of atoms to learn.</p>
</dd>
<dt><strong>n_times_atom</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The support of the atom.</p>
</dd>
<dt><strong>reg</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">The regularization parameter</p>
</dd>
<dt><strong>lmbd_max</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘fixed’ | ‘scaled’ | ‘per_atom’ | ‘shared’</span></dt>
<dd><dl class="first last docutils">
<dt>If not fixed, adapt the regularization rate as a ratio of lambda_max:</dt>
<dd><ul class="first last simple">
<li>‘scaled’: the regularization parameter is fixed as a ratio of its
maximal value at init i.e. reg_used = reg * lmbd_max(uv_init)</li>
<li>‘shared’: the regularization parameter is set at each iteration as
a ratio of its maximal value for the current dictionary estimate
i.e. reg_used = reg * lmbd_max(uv_hat)</li>
<li>‘per_atom’: the regularization parameter is set per atom and at
each iteration as a ratio of its maximal value for this atom i.e.
reg_used[k] = reg * lmbd_max(uv_hat[k])</li>
</ul>
</dd>
</dl>
</dd>
<dt><strong>n_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The number of coordinate-descent iterations.</p>
</dd>
<dt><strong>n_jobs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The number of parallel jobs.</p>
</dd>
<dt><strong>loss</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘l2’ | ‘dtw’</span></dt>
<dd><p class="first last">Loss for the data-fit term. Either the norm l2 or the soft-DTW.</p>
</dd>
<dt><strong>loss_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Parameters of the loss</p>
</dd>
<dt><strong>rank1</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd><p class="first last">If set to True, learn rank 1 dictionary atoms.</p>
</dd>
<dt><strong>uv_constraint</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str in {‘joint’ | ‘separate’}</span></dt>
<dd><p class="first last">The kind of norm constraint on the atoms:
If ‘joint’, the constraint is norm_2([u, v]) &lt;= 1
If ‘separate’, the constraint is norm_2(u) &lt;= 1 and norm_2(v) &lt;= 1</p>
</dd>
<dt><strong>eps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Stopping criterion. If the cost descent after a uv and a z update is
smaller than eps, return.</p>
</dd>
<dt><strong>algorithm</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘batch’ | ‘greedy’ | ‘online’</span></dt>
<dd><p class="first last">Dictionary learning algorithm.</p>
</dd>
<dt><strong>algorithm_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><dl class="first last docutils">
<dt>Parameters for the global algorithm used to learn the dictionary:</dt>
<dd><dl class="first last docutils">
<dt>alpha <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Forgetting factor for online learning. If set to 0, the learning is
stochastic and each D-step is independent from the previous steps.
When set to 1, each the previous values z_hat - computed with
different dictionary - have the same weight as the current one.
This factor should be large enough to ensure convergence but to
large factor can lead to sub-optimal minima.</p>
</dd>
<dt>batch_selection <span class="classifier-delimiter">:</span> <span class="classifier">‘random’ | ‘cyclic’</span></dt>
<dd><p class="first last">The batch selection strategy for online learning. The batch are
either selected randomly among all samples (without replacement) or
in a cyclic way.</p>
</dd>
<dt>batch_size <span class="classifier-delimiter">:</span> <span class="classifier">int in [1, n_trials]</span></dt>
<dd><p class="first last">Size of the batch used in online learning. Increasing it
regularizes the dictionary learning as there is less variance for
the successive estimates. But it also increases the computational
cost as more coding signals z_hat must be estimate at each
iteration.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt><strong>solver_z</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">The solver to use for the z update. Options are
‘l-bfgs’ (default) | “lgcd”</p>
</dd>
<dt><strong>solver_z_kwargs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword arguments to pass to update_z_multi</p>
</dd>
<dt><strong>solver_d</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">The solver to use for the d update. Options are
‘alternate’ | ‘alternate_adaptive’ (default) | ‘joint’</p>
</dd>
<dt><strong>solver_d_kwargs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Additional keyword arguments to provide to update_d</p>
</dd>
<dt><strong>D_init</strong> <span class="classifier-delimiter">:</span> <span class="classifier">str or array, shape (n_atoms, n_channels + n_times_atoms) or                            shape (n_atoms, n_channels, n_times_atom)</span></dt>
<dd><p class="first last">The initial atoms or an initialization scheme in {‘kmeans’ | ‘ssa’ |
‘chunk’ | ‘random’}.</p>
</dd>
<dt><strong>D_init_params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict</span></dt>
<dd><p class="first last">Dictionnary of parameters for the kmeans init method.</p>
</dd>
<dt><strong>unbiased_z_hat</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd><p class="first last">If set to True, the value of the non-zero coefficients in the returned
z_hat are recomputed with reg=0 on the frozen support.</p>
</dd>
<dt><strong>use_sparse_z</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd><p class="first last">Use sparse lil_matrices to store the activations.</p>
</dd>
<dt><strong>verbose</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">The verbosity level.</p>
</dd>
<dt><strong>callback</strong> <span class="classifier-delimiter">:</span> <span class="classifier">func</span></dt>
<dd><p class="first last">A callback function called at the end of each loop of the
coordinate descent.</p>
</dd>
<dt><strong>random_state</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int | None</span></dt>
<dd><p class="first last">The random state.</p>
</dd>
<dt><strong>raise_on_increase</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd><p class="first last">Raise an error if the objective function increase</p>
</dd>
<dt><strong>window</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd><p class="first last">If True, re-parametrizes the atoms with a temporal Tukey window</p>
</dd>
<dt><strong>sort_atoms</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean</span></dt>
<dd><p class="first last">If True, the atoms are sorted by explained variances.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>pobj</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd><p class="first last">The objective function value at each step of the coordinate descent.</p>
</dd>
<dt><strong>times</strong> <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd><p class="first last">The cumulative time for each iteration of the coordinate descent.</p>
</dd>
<dt><strong>uv_hat</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_atoms, n_channels + n_times_atom)</span></dt>
<dd><p class="first last">The atoms to learn from the data.</p>
</dd>
<dt><strong>z_hat</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_trials, n_atoms, n_times_valid)</span></dt>
<dd><p class="first last">The sparse activation matrix.</p>
</dd>
<dt><strong>reg</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">Regularization parameter used.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2017-2018, Mainak Jas.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>