<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>alphacsc.learn_d_z_multi &#8212; alphacsc 0.3 documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="alphacsc.learn_d_z_weighted" href="alphacsc.learn_d_z_weighted.html" />
    <link rel="prev" title="alphacsc.learn_d_z" href="alphacsc.learn_d_z.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          alphacsc</a>
        <span class="navbar-text navbar-version pull-left"><b>0.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../models.html">Models</a></li>
                <li><a href="../auto_examples/index.html">Examples</a></li>
                <li><a href="../api.html">API</a></li>
                <li><a href="https://github.com/alphacsc/alphacsc">GitHub</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">alphaCSC: Convolution sparse coding for time-series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">Model descriptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples Gallery</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/alphacsc/alphacsc">Fork alphacsc on Github</a></li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="alphacsc-learn-d-z-multi">
<h1>alphacsc.learn_d_z_multi<a class="headerlink" href="#alphacsc-learn-d-z-multi" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="alphacsc.learn_d_z_multi">
<code class="sig-prename descclassname">alphacsc.</code><code class="sig-name descname">learn_d_z_multi</code><span class="sig-paren">(</span><em class="sig-param">X</em>, <em class="sig-param">n_atoms</em>, <em class="sig-param">n_times_atom</em>, <em class="sig-param">n_iter=60</em>, <em class="sig-param">n_jobs=1</em>, <em class="sig-param">lmbd_max='fixed'</em>, <em class="sig-param">reg=0.1</em>, <em class="sig-param">loss='l2'</em>, <em class="sig-param">loss_params={'gamma': 0.1</em>, <em class="sig-param">'sakoe_chiba_band': 10</em>, <em class="sig-param">'ordar': 10}</em>, <em class="sig-param">rank1=True</em>, <em class="sig-param">uv_constraint='separate'</em>, <em class="sig-param">eps=1e-10</em>, <em class="sig-param">algorithm='batch'</em>, <em class="sig-param">algorithm_params={}</em>, <em class="sig-param">detrending=None</em>, <em class="sig-param">detrending_params={}</em>, <em class="sig-param">solver_z='l-bfgs'</em>, <em class="sig-param">solver_z_kwargs={}</em>, <em class="sig-param">solver_d='alternate_adaptive'</em>, <em class="sig-param">solver_d_kwargs={}</em>, <em class="sig-param">D_init=None</em>, <em class="sig-param">D_init_params={}</em>, <em class="sig-param">unbiased_z_hat=False</em>, <em class="sig-param">use_sparse_z=False</em>, <em class="sig-param">stopping_pobj=None</em>, <em class="sig-param">raise_on_increase=True</em>, <em class="sig-param">verbose=10</em>, <em class="sig-param">callback=None</em>, <em class="sig-param">random_state=None</em>, <em class="sig-param">name='DL'</em>, <em class="sig-param">window=False</em>, <em class="sig-param">sort_atoms=False</em><span class="sig-paren">)</span><a class="headerlink" href="#alphacsc.learn_d_z_multi" title="Permalink to this definition">¶</a></dt>
<dd><p>Multivariate Convolutional Sparse Coding with optional rank-1 constraint</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array, shape (n_trials, n_channels, n_times)</span></dt><dd><p>The data on which to perform CSC.</p>
</dd>
<dt><strong>n_atoms</strong><span class="classifier">int</span></dt><dd><p>The number of atoms to learn.</p>
</dd>
<dt><strong>n_times_atom</strong><span class="classifier">int</span></dt><dd><p>The support of the atom.</p>
</dd>
<dt><strong>reg</strong><span class="classifier">float</span></dt><dd><p>The regularization parameter</p>
</dd>
<dt><strong>lmbd_max</strong><span class="classifier">‘fixed’ | ‘scaled’ | ‘per_atom’ | ‘shared’</span></dt><dd><dl class="simple">
<dt>If not fixed, adapt the regularization rate as a ratio of lambda_max:</dt><dd><ul class="simple">
<li><p>‘scaled’: the regularization parameter is fixed as a ratio of its
maximal value at init i.e. reg_used = reg * lmbd_max(uv_init)</p></li>
<li><p>‘shared’: the regularization parameter is set at each iteration as
a ratio of its maximal value for the current dictionary estimate
i.e. reg_used = reg * lmbd_max(uv_hat)</p></li>
<li><p>‘per_atom’: the regularization parameter is set per atom and at
each iteration as a ratio of its maximal value for this atom i.e.
reg_used[k] = reg * lmbd_max(uv_hat[k])</p></li>
</ul>
</dd>
</dl>
</dd>
<dt><strong>n_iter</strong><span class="classifier">int</span></dt><dd><p>The number of coordinate-descent iterations.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">int</span></dt><dd><p>The number of parallel jobs.</p>
</dd>
<dt><strong>loss</strong><span class="classifier">‘l2’ | ‘dtw’</span></dt><dd><p>Loss for the data-fit term. Either the norm l2 or the soft-DTW.</p>
</dd>
<dt><strong>loss_params</strong><span class="classifier">dict</span></dt><dd><p>Parameters of the loss</p>
</dd>
<dt><strong>rank1</strong><span class="classifier">boolean</span></dt><dd><p>If set to True, learn rank 1 dictionary atoms.</p>
</dd>
<dt><strong>uv_constraint</strong><span class="classifier">str in {‘joint’ | ‘separate’}</span></dt><dd><p>The kind of norm constraint on the atoms:
If ‘joint’, the constraint is norm_2([u, v]) &lt;= 1
If ‘separate’, the constraint is norm_2(u) &lt;= 1 and norm_2(v) &lt;= 1</p>
</dd>
<dt><strong>eps</strong><span class="classifier">float</span></dt><dd><p>Stopping criterion. If the cost descent after a uv and a z update is
smaller than eps, return.</p>
</dd>
<dt><strong>algorithm</strong><span class="classifier">‘batch’ | ‘greedy’ | ‘online’</span></dt><dd><p>Dictionary learning algorithm.</p>
</dd>
<dt><strong>algorithm_params</strong><span class="classifier">dict</span></dt><dd><dl class="simple">
<dt>Parameters for the global algorithm used to learn the dictionary:</dt><dd><dl class="simple">
<dt>alpha<span class="classifier">float</span></dt><dd><p>Forgetting factor for online learning. If set to 0, the learning is
stochastic and each D-step is independent from the previous steps.
When set to 1, each the previous values z_hat - computed with
different dictionary - have the same weight as the current one.
This factor should be large enough to ensure convergence but to
large factor can lead to sub-optimal minima.</p>
</dd>
<dt>batch_selection<span class="classifier">‘random’ | ‘cyclic’</span></dt><dd><p>The batch selection strategy for online learning. The batch are
either selected randomly among all samples (without replacement) or
in a cyclic way.</p>
</dd>
<dt>batch_size<span class="classifier">int in [1, n_trials]</span></dt><dd><p>Size of the batch used in online learning. Increasing it
regularizes the dictionary learning as there is less variance for
the successive estimates. But it also increases the computational
cost as more coding signals z_hat must be estimate at each
iteration.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt><strong>solver_z</strong><span class="classifier">str</span></dt><dd><p>The solver to use for the z update. Options are
‘l-bfgs’ (default) | “lgcd”</p>
</dd>
<dt><strong>solver_z_kwargs</strong><span class="classifier">dict</span></dt><dd><p>Additional keyword arguments to pass to update_z_multi</p>
</dd>
<dt><strong>solver_d</strong><span class="classifier">str</span></dt><dd><p>The solver to use for the d update. Options are
‘alternate’ | ‘alternate_adaptive’ (default) | ‘joint’</p>
</dd>
<dt><strong>solver_d_kwargs</strong><span class="classifier">dict</span></dt><dd><p>Additional keyword arguments to provide to update_d</p>
</dd>
<dt><strong>D_init</strong><span class="classifier">str or array, shape (n_atoms, n_channels + n_times_atoms) or                            shape (n_atoms, n_channels, n_times_atom)</span></dt><dd><p>The initial atoms or an initialization scheme in {‘kmeans’ | ‘ssa’ |
‘chunk’ | ‘random’}.</p>
</dd>
<dt><strong>D_init_params</strong><span class="classifier">dict</span></dt><dd><p>Dictionnary of parameters for the kmeans init method.</p>
</dd>
<dt><strong>unbiased_z_hat</strong><span class="classifier">boolean</span></dt><dd><p>If set to True, the value of the non-zero coefficients in the returned
z_hat are recomputed with reg=0 on the frozen support.</p>
</dd>
<dt><strong>use_sparse_z</strong><span class="classifier">boolean</span></dt><dd><p>Use sparse lil_matrices to store the activations.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">int</span></dt><dd><p>The verbosity level.</p>
</dd>
<dt><strong>callback</strong><span class="classifier">func</span></dt><dd><p>A callback function called at the end of each loop of the
coordinate descent.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int | None</span></dt><dd><p>The random state.</p>
</dd>
<dt><strong>raise_on_increase</strong><span class="classifier">boolean</span></dt><dd><p>Raise an error if the objective function increase</p>
</dd>
<dt><strong>window</strong><span class="classifier">boolean</span></dt><dd><p>If True, re-parametrizes the atoms with a temporal Tukey window</p>
</dd>
<dt><strong>sort_atoms</strong><span class="classifier">boolean</span></dt><dd><p>If True, the atoms are sorted by explained variances.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>pobj</strong><span class="classifier">list</span></dt><dd><p>The objective function value at each step of the coordinate descent.</p>
</dd>
<dt><strong>times</strong><span class="classifier">list</span></dt><dd><p>The cumulative time for each iteration of the coordinate descent.</p>
</dd>
<dt><strong>uv_hat</strong><span class="classifier">array, shape (n_atoms, n_channels + n_times_atom)</span></dt><dd><p>The atoms to learn from the data.</p>
</dd>
<dt><strong>z_hat</strong><span class="classifier">array, shape (n_trials, n_atoms, n_times_valid)</span></dt><dd><p>The sparse activation matrix.</p>
</dd>
<dt><strong>reg</strong><span class="classifier">float</span></dt><dd><p>Regularization parameter used.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2017-2018, Mainak Jas.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.1.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>